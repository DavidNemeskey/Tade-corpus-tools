{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# About this notebook\n",
    "\n",
    "This notebook was written for the [2016 Construction grammar course](http://budling.hu/elmnyelv/index.php/Constructions2016) at the [Department of Theoretical Linguistics](http://www.nytud.hu/tlp/index.html). Its main aim is to provide easier access to the [Tádé korpusz](http://hlt.bme.hu/hu/resources/tade), on which most of the experiments in the course are based.\n",
    "\n",
    "## Basic setup\n",
    "\n",
    "The first part of the file shows how to download the corpus to your computer and then how to load it into a [Pandas](http://pandas.pydata.org/) *dataframe* (i.e. table). The best way to set up your own experiments is to copy this file, rename it something else (e.g. *my_fruitful_experiments**.ipynb***), and load that notebook: in this way, you won't have to worry about all this boilerplate, and you will be able to start crunching at those verb frame frequencies right away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# So that plots work correctly\n",
    "%matplotlib inline   \n",
    "\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the code in this notebook creates files in the current directory, i.e. the one from which you started the notebook. To use a different directory, just change the value of the `work_directory` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory is: /run/shm/Tade-corpus-tools/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "work_directory = os.path.abspath('.')\n",
    "data_file = 'tade.tsv'\n",
    "\n",
    "if not os.path.isdir(work_directory):\n",
    "    os.makedirs(work_directory)\n",
    "os.chdir(work_directory)\n",
    "\n",
    "print(\"The working directory is: \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Getting the data into a table\n",
    "\n",
    "The first step is to download the Tádé file if it is not downloaded yet. Remember to execute the cell above before this one so that you are in the data directory you specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(data_file):\n",
    "    import urllib\n",
    "    u = urllib.request.URLopener()\n",
    "    print('Downloading Tádé')\n",
    "    u.retrieve('http://people.mokk.bme.hu/~recski/verb_clusters/tade.tsv', 'tade.tsv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the file, we can read it into a `DataFrame` and start working on our experiments... The file is in the Latin-2 (ISO-8859-2) encoding, which is not the default in Python (nor in the modern world) -- that title belongs to utf-8. So in order to be able to properly load the file, we need to specify the encoding as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tade.tsv; read 1158484 lines. The first five lines are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>frame_freq</th>\n",
       "      <th>verb_freq</th>\n",
       "      <th>freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>van</td>\n",
       "      <td>@</td>\n",
       "      <td>362298</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.398643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>van</td>\n",
       "      <td>NP&lt;CAS&lt;INE&gt;&gt;</td>\n",
       "      <td>71800</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.079003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>van</td>\n",
       "      <td>NP&lt;CAS&lt;DAT&gt;&gt;</td>\n",
       "      <td>56905</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.062614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>van</td>\n",
       "      <td>NP&lt;CAS&lt;SBL&gt;&gt;</td>\n",
       "      <td>35869</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.039467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>van</td>\n",
       "      <td>NP&lt;CAS&lt;SUE&gt;&gt;</td>\n",
       "      <td>29836</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.032829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verb         frame  frame_freq  verb_freq  freq_ratio\n",
       "0  van             @      362298     908829    0.398643\n",
       "1  van  NP<CAS<INE>>       71800     908829    0.079003\n",
       "2  van  NP<CAS<DAT>>       56905     908829    0.062614\n",
       "3  van  NP<CAS<SBL>>       35869     908829    0.039467\n",
       "4  van  NP<CAS<SUE>>       29836     908829    0.032829"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['verb', 'frame', 'frame_freq', 'verb_freq', 'freq_ratio']\n",
    "df = pd.read_table(data_file, encoding='latin2', sep='\\t', names=column_names)\n",
    "print('Loaded ' + data_file + '; read ' + str(len(df)) + ' lines. The first five lines are:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few examples\n",
    "\n",
    "To give you an idea of Pandas in action, this section lists a few examples, in which we extract various statistics from the data. Let's dig in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many different verbs are in the corpus?\n",
    "\n",
    "In other words, the number of unique elements in column one (`verb`). There are several ways to find it out:\n",
    "\n",
    "1. Have Pandas [`describe()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.describe.html) the column for you. What it shows depends on the type of the column; for strings, the description will have a `unique` field. What do you think the other fields mean?\n",
    "2. Just call the [`unique()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html) function on the column. This returns an array of all the unique elements; all you need is to take the length of the array.\n",
    "3. Or just do (2) in a single step with [`nunique()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.nunique.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "describe()-based solution:\n",
      "\n",
      "count     1158484\n",
      "unique     108045\n",
      "top           van\n",
      "freq        15337\n",
      "Name: verb, dtype: object \n",
      "\n",
      "Unique only:  108045 \n",
      "\n",
      "\n",
      "unique()-based solution: 108045 \n",
      "\n",
      "\n",
      "nunique()-based solution: 108045\n"
     ]
    }
   ],
   "source": [
    "print('describe()-based solution:\\n')    # \\n means new line (i.e. Enter, Return, etc.)\n",
    "desc = df.verb.describe()\n",
    "print(desc, '\\n')\n",
    "print('Unique only: ', desc['unique'], '\\n\\n')\n",
    "\n",
    "print('unique()-based solution:', len(df.verb.unique()), '\\n\\n')\n",
    "print('nunique()-based solution:', df.verb.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In all, how many frames did we extract from our corpus?\n",
    "\n",
    "Once again, there are different ways of doing this; for instance:\n",
    "\n",
    "1. Sum the frame counts of all the different verb-frame pairs.\n",
    "2. Notice that if we sum up the frame counts, we get the verb frequency. So we need only `sum()` the verb frequencies for each word. Now, this way is a bit longer:\n",
    "  1. First, we do not need to work on the whole table, only the verbs and their counts; therefore, we extract these two columns to a new table.\n",
    "  2. Then, we group this new table by the verbs; this gives us a [`Groupby`](http://pandas.pydata.org/pandas-docs/stable/api.html#groupby) object\n",
    "  3. Since the verb frequencies are the same in all rows for a verb, we only need the `first()` row in each group\n",
    "  4. Finally, we can `sum()` the filtered column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of frame counts:  9966153\n",
      "Sum of verb counts:  9966153\n"
     ]
    }
   ],
   "source": [
    "print('Sum of frame counts: ', df.frame_freq.sum())\n",
    "\n",
    "df_verb_and_freq = df[['verb', 'verb_freq']]\n",
    "verb_and_freq_groups = df_verb_and_freq.groupby('verb')  # verb -> [verb_freq, verb_freq, verb_freq, ...]\n",
    "verb_freqs = verb_and_freq_groups.first()                # verb -> verb_freq\n",
    "\n",
    "print('Sum of verb counts: ', verb_freqs.verb_freq.sum())\n",
    "\n",
    "# This works too: df[['verb', 'verb_freq']].groupby('verb').first().verb_freq.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
