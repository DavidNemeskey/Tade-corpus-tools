{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# About this notebook\n",
    "\n",
    "This notebook was written for the [2016 Construction grammar course](http://budling.hu/elmnyelv/index.php/Constructions2016) at the [Department of Theoretical Linguistics](http://www.nytud.hu/tlp/index.html). In this experiment, we try to establish if there are preverbs which correlate with certain argument types to a statistically significant extent. This is also an introductory notebook, which touches on some advanced topics, such as `DataFrame` joining and data plotting. For the first part of the introduction, refer to the [Pandas tutorial](Pandas tutorial.ipynb)\n",
    "\n",
    "## Basic setup\n",
    "\n",
    "The first part of the file shows how to download the corpus to your computer and then how to load it into a [Pandas](http://pandas.pydata.org/) *dataframe* (i.e. table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# So that plots work correctly\n",
    "%matplotlib inline   \n",
    "\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the code in this notebook creates files in the current directory, i.e. the one from which you started the notebook. To use a different directory, just change the value of the `work_directory` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory is: /run/shm/Tade-corpus-tools/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "work_directory = os.path.abspath('.')\n",
    "data_file = 'tade.tsv'\n",
    "\n",
    "if not os.path.isdir(work_directory):\n",
    "    os.makedirs(work_directory)\n",
    "os.chdir(work_directory)\n",
    "\n",
    "print(\"The working directory is: \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up plotting. It would work without these commands (since we imported `matplotlib` above), but it looks nicer this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "#pd.set_option('display.mpl_style', 'default')\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = (15, 3)\n",
    "matplotlib.pyplot.rcParams['font.family'] = 'sans-serif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Getting the data into a table\n",
    "\n",
    "The first step is to download the Tádé file if it is not downloaded yet. Remember to execute the cell above before this one so that you are in the data directory you specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tádé is already downloaded.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_file):\n",
    "    import urllib\n",
    "    u = urllib.request.URLopener()\n",
    "    print('Downloading Tádé...')\n",
    "    u.retrieve('http://people.mokk.bme.hu/~recski/verb_clusters/tade.tsv', 'tade.tsv')\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('Tádé is already downloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the file, we can read it into a `DataFrame` and start working on our experiments... The file is in the Latin-2 (ISO-8859-2) encoding, which is not the default in Python (nor in the modern world) -- that title belongs to utf-8. So in order to be able to properly load the file, we need to specify the encoding as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tade.tsv; read 1158484 lines. The first five lines are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>frame</th>\n",
       "      <th>frame_freq</th>\n",
       "      <th>verb_freq</th>\n",
       "      <th>freq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>van</td>\n",
       "      <td>@</td>\n",
       "      <td>362298</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.398643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>van</td>\n",
       "      <td>NP&lt;CAS&lt;INE&gt;&gt;</td>\n",
       "      <td>71800</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.079003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>van</td>\n",
       "      <td>NP&lt;CAS&lt;DAT&gt;&gt;</td>\n",
       "      <td>56905</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.062614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>van</td>\n",
       "      <td>NP&lt;CAS&lt;SBL&gt;&gt;</td>\n",
       "      <td>35869</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.039467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>van</td>\n",
       "      <td>NP&lt;CAS&lt;SUE&gt;&gt;</td>\n",
       "      <td>29836</td>\n",
       "      <td>908829</td>\n",
       "      <td>0.032829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  verb         frame  frame_freq  verb_freq  freq_ratio\n",
       "0  van             @      362298     908829    0.398643\n",
       "1  van  NP<CAS<INE>>       71800     908829    0.079003\n",
       "2  van  NP<CAS<DAT>>       56905     908829    0.062614\n",
       "3  van  NP<CAS<SBL>>       35869     908829    0.039467\n",
       "4  van  NP<CAS<SUE>>       29836     908829    0.032829"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['verb', 'frame', 'frame_freq', 'verb_freq', 'freq_ratio']\n",
    "df = pd.read_table(data_file, encoding='latin2', sep='\\t', names=column_names)\n",
    "print('Loaded ' + data_file + '; read ' + str(len(df)) + ' lines. The first five lines are:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant Arguments\n",
    "\n",
    "Now we can start with the real experiment. We will use [Fisher's exact test](https://en.wikipedia.org/wiki/Fisher's_exact_test) to evaluate the correlation between preverb and argument. An implementation is available in the [scipy library](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.fisher_exact.html), which was brought along by Pandas. Basically what we will measure is the odds of a preverb co-occuring with and without an argument (e.g. _rá_ and _CAS&lt;SBL&gt;_, and _rá_ only) vs the same odds for verbs without the preverb (i.e. frames with and without _CAS&lt;SBL&gt;_). This will give us the so called _p-value_, which tells us the probability of the the correlation **NOT** holding.\n",
    "\n",
    "### Data transformations\n",
    "\n",
    "Unfortunately, the data, in its current format, is not the best suited for the calculations we need. So a few transformations are in order:\n",
    "\n",
    "1. The _INF_ frame is not recorded explicitly in the `frame` column; rather, the lemma of infinite verb is appended to the finite one, e.g. `akar_fut`. For such rows, we will delete the part after the underscore and add _INF_ to the frame.\n",
    "1. The empty frame is marked with an at sign (`@`). Since we don't care about those (but we could!), we shall change these frames to `np.nan`. The _NaN_ (Not a Number) value tells Pandas that the cell is empty, and is valid for all column types (as opposed to e.g. 0, which is only valid for numeric columns). An added bonus is that such cells are not taken into account when grouping by the column, which we will need to do.\n",
    "1. Actually, we don't really care about the verbs at all, only the preverbs. So we will add a column to the frame that stores only the preverb, i.e. the part before the `+` in verbs such as `meg+próbál`.\n",
    "1. Finally, if there is a compound argument, such as `NP<CAS<ACC>>_NP<CAS<DAT>>`, we will have to count it both for _ACC_ and _DAT_. It will be much easier if we split such rows into as many rows as there are arguments, and just have a single argument per row. So in this case, we duplicate the row, and keep each cell as-is, with the exception of `frame`, which will be `NP<CAS<ACC>>` in the first row and `NP<CAS<DAT>>` in the second.\n",
    "\n",
    "The functions below implement these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_frames(df):\n",
    "    \"\"\"\n",
    "    Splits the frames into individual arguments and creates as many copies of the row\n",
    "    as there are arguments in the frame. Makes certain calculations easier.\n",
    "    \"\"\"\n",
    "    s = df.frame.str.split('_').apply(pd.Series, 1).stack()\n",
    "    s.index = s.index.droplevel(-1)  # Drops the second-level index (0, 1, ...) created by stack()\n",
    "    s.name = 'frame'                 # Needs a name for join\n",
    "    return df.drop('frame', axis=1).join(s)[df.columns]  # Keep the original column order\n",
    "\n",
    "def normalize_frames(df, in_place=True):\n",
    "    \"\"\"\n",
    "    This function does two things: first, it adds INF as a frame if the verb is a modal\n",
    "    (i.e. the 'verb' column is of the format FiniteVerb_InfiniteVerb). Second, it replaces\n",
    "    the '@' (empty) frame marker with numpy.nan for better grouping support later on.\n",
    "    \"\"\"\n",
    "    df_ret = df if in_place else df.copy(deep=True)\n",
    "    df_ret.frame = df_ret.frame.apply(lambda s: 'INF' if s == '@' else s + '_INF').where(\n",
    "        df_ret.verb.str.contains('_', regex=False), other=df_ret.frame)\n",
    "    df_ret.loc[df_ret.verb.str.contains('_', regex=False), 'verb'] = df_ret.verb.str.replace('_.*', '')\n",
    "    df_ret.loc[df_ret.frame == '@', 'frame'] = np.nan\n",
    "    return df_ret\n",
    "\n",
    "def add_preverb_column(df):\n",
    "    \"\"\"Adds a preverb column to the data frame.\"\"\"\n",
    "    return df.assign(preverb=df.verb.str.replace('[+].+', '').where(df.verb.str.contains('+', regex=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Running the functions above on our table results in a much easier-to-handle one. One thing that is really a one-liner now is to get the number of times each preverb or argument occurs in the corpus; it is just a matter of grouping the table and aggregating the rows:\n",
    "\n",
    "1. If we aggregate with `count()` (the column is not important in this case), we will get for each preverb the number of verbs it attaches to.\n",
    "1. If we aggregate the `frame_freq` column by `frame` with `sum()`, we get the raw number of times an argument occurs in the corpus.\n",
    "1. Finally, aggregating the `frame_freq` column by `preverb` with `sum()` tells us the number of times each preverb occurs. However, we should do it **before** splitting the frames, otherwise the duplicated frequencies that help us in the second case mess up things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_preverbs = add_preverb_column(df)\n",
    "df_to_join = split_frames(normalize_frames(df_with_preverbs))\n",
    "\n",
    "preverb_counts = df_with_preverbs[['preverb', 'verb']].rename(columns={'verb': 'count'}).groupby('preverb').count()\n",
    "\n",
    "preverb_sums = df_with_preverbs[['preverb', 'frame_freq']].rename(columns={'frame_freq': 'B'}).groupby('preverb').sum()\n",
    "frame_sums = df_to_join[['frame', 'frame_freq']].rename(columns={'frame_freq': 'C'}).groupby('frame').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names (_A_, _B_, _C_, _D_ are the same as on the [Wikipedia page](https://en.wikipedia.org/wiki/Fisher's_exact_test).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_frames = df.frame_freq.sum()\n",
    "\n",
    "df_to_join = split_frames(normalize_frames(add_preverb_column(df2)))\n",
    "\n",
    "frame_counts = df_to_join[['frame', 'verb']].rename(columns={'verb': 'count'}).groupby('frame').count()\n",
    "preverb_counts = df_to_join[['preverb', 'verb']].rename(columns={'verb': 'count'}).groupby('preverb').count()\n",
    "display(frame_counts)\n",
    "display(preverb_counts)\n",
    "\n",
    "frame_sums = df2[['frame', 'frame_freq']].rename(columns={'frame_freq': 'C'}).groupby('frame').sum()\n",
    "preverb_sums = df2[['preverb', 'frame_freq']].rename(columns={'frame_freq': 'B'}).groupby('preverb').sum()\n",
    "cells = df2[['frame', 'preverb', 'frame_freq']].rename(columns={'frame_freq': 'A'}).groupby(['preverb', 'frame']).sum()\n",
    "print(cells)\n",
    "print(frame_sums)\n",
    "print(preverb_sums)\n",
    "display(cells)\n",
    "display(preverb_sums)\n",
    "display(frame_sums)\n",
    "\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "full = cells.join(preverb_sums).join(frame_sums)\n",
    "full['D'] = all_frames + full.A - full.B - full.C\n",
    "full['Fisher'] = full.apply(lambda row: scipy.stats.fisher_exact([[row.A, row.B - row.A], [row.C, row.D - row.C]])[1], axis=1)\n",
    "display(full)\n",
    "\n",
    "#aha = pd.DataFrame({'apple': [0, 1, 2], 'banana': [3, 4, 5], 'cherry': ['good', 'bad', 'good']})\n",
    "#aha['apple'][aha.cherry == 'bad'] = np.nan\n",
    "#aha.loc[aha.cherry == 'bad', ['apple', 'banana']] = aha.loc[aha.cherry == 'bad', ['banana', 'apple']]\n",
    "#aha.loc[aha.cherry == 'bad', 'apple'] = aha.banana + 1\n",
    "#display(aha)\n",
    "#aha.loc[aha.cherry == 'good', ['apple', 'banana']] = (aha[['banana','apple']] * 2).values\n",
    "#aha.loc[aha.cherry == 'good', ['apple', 'banana']] = pd.concat([aha['banana'] * 3, aha['apple'] * 2], axis=1)\n",
    "#display(aha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
